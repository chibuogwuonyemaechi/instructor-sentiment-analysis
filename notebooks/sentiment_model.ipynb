{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34c74a9-ba5e-4fcf-bc31-d2214929127a",
   "metadata": {},
   "source": [
    "## Import basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92dbd93b-a0ea-486f-8378-f15ab3b49389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "065e3785-96f4-41ef-b4e4-1eef7fca939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ochib\\anaconda3\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\ochib\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ochib\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: gensim in c:\\users\\ochib\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ochib\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ochib\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: streamlit in c:\\users\\ochib\\anaconda3\\lib\\site-packages (1.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (16.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.66.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ochib\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 624.3/624.3 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn textblob gensim matplotlib seaborn streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3b83c44-a619-4e30-8620-e44d1b4a4965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\ochib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ochib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ochib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\ochib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\ochib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\ochib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed36e2e8-24e7-4644-91f9-fa29ffcca8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a2b99-a5ff-46db-9566-7602a1bdd2df",
   "metadata": {},
   "source": [
    "# Narration:\n",
    "In this step, we import essential Python libraries such as `pandas`, `numpy`, `textblob`, `gensim`, and visualization tools like `matplotlib` and `seaborn`. These packages are crucial for data manipulation, natural language processing, machine learning, and visual storytelling.\n",
    "\n",
    "📌 *Why it matters*: Efficient library management ensures our pipeline is reproducible, and aligned with the tool stack mentioned in the project brief (TextBlob, LDA, Power BI). It sets up the computational environment for all downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbebecd-8268-411f-aff3-7b5ec9ea53f1",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "865defde-04cc-4558-bbdc-b735f5b6aa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>instructor_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rating_score</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2889</td>\n",
       "      <td>21</td>\n",
       "      <td>69</td>\n",
       "      <td>The instructor was very clear and made the cou...</td>\n",
       "      <td>3/4/2025</td>\n",
       "      <td>5</td>\n",
       "      <td>17.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2581</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>Too fast-paced and lacked clear explanations.</td>\n",
       "      <td>10/11/2024</td>\n",
       "      <td>2</td>\n",
       "      <td>10.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>Not engaging at all. I struggled to stay focus...</td>\n",
       "      <td>3/5/2025</td>\n",
       "      <td>1</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>145</td>\n",
       "      <td>The instructor was fine, but the pace felt a b...</td>\n",
       "      <td>5/20/2024</td>\n",
       "      <td>3</td>\n",
       "      <td>66.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1668</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>The course was okay, but I expected more pract...</td>\n",
       "      <td>3/28/2025</td>\n",
       "      <td>3</td>\n",
       "      <td>29.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  student_id  instructor_id  course_id  \\\n",
       "0          1        2889             21         69   \n",
       "1          2        2581             46        130   \n",
       "2          3         344             48         20   \n",
       "3          4           2             70        145   \n",
       "4          5        1668             48         58   \n",
       "\n",
       "                                         review_text review_date  \\\n",
       "0  The instructor was very clear and made the cou...    3/4/2025   \n",
       "1      Too fast-paced and lacked clear explanations.  10/11/2024   \n",
       "2  Not engaging at all. I struggled to stay focus...    3/5/2025   \n",
       "3  The instructor was fine, but the pace felt a b...   5/20/2024   \n",
       "4  The course was okay, but I expected more pract...   3/28/2025   \n",
       "\n",
       "   rating_score  response_time  \n",
       "0             5          17.74  \n",
       "1             2          10.87  \n",
       "2             1           4.10  \n",
       "3             3          66.74  \n",
       "4             3          29.10  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "instructors = pd.read_csv(r\"C:\\Users\\ochib\\Downloads\\DSProject 2\\Data 1 Instructors.csv\")\n",
    "courses = pd.read_csv(r\"C:\\Users\\ochib\\Downloads\\DSProject 2\\Data 2 Coursrs.csv\")\n",
    "students = pd.read_csv(r\"C:\\Users\\ochib\\Downloads\\DSProject 2\\Data 3 Students.csv\")\n",
    "reviews = pd.read_csv(r\"C:\\Users\\ochib\\Downloads\\DSProject 2\\Data 4 Reviews.csv\")\n",
    "\n",
    "# Preview the review data\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "260326c2-a1da-4a05-8e70-3c8a8dedb957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75 entries, 0 to 74\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   instructor_id      75 non-null     int64  \n",
      " 1   full_name          75 non-null     object \n",
      " 2   country            75 non-null     object \n",
      " 3   experience_years   75 non-null     int64  \n",
      " 4   course_count       75 non-null     int64  \n",
      " 5   avg_response_time  75 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 3.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Data verification - Data type, number of features and rows, missing data, etc\n",
    "instructors.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e908c6c3-ae7b-487a-8e81-56fdac3cf0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   course_id       150 non-null    int64  \n",
      " 1   title           150 non-null    object \n",
      " 2   category        150 non-null    object \n",
      " 3   language        150 non-null    object \n",
      " 4   duration_hours  150 non-null    float64\n",
      " 5   level           150 non-null    object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Data verification - Data type, number of features and rows, missing data, etc\n",
    "courses.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf397070-c0fd-4f6c-bd3c-67a4201d93f9",
   "metadata": {},
   "source": [
    "# Narration:\n",
    "We load four key CSV files: Instructors, Courses, Students, and Reviews. These datasets are interlinked via foreign keys like `student_id`, `instructor_id`, and `course_id`.\n",
    "\n",
    "📌 *Why it matters*: According to the data dictionary and the brief, these four datasets form the foundation of our relational model. Understanding their schema early helps establish a clean, connected analytical environment necessary for sentiment tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad8fed4-3c15-4ec7-aee4-7c5167617309",
   "metadata": {},
   "source": [
    "## Data Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2817a067-375e-486d-8ada-ad1aeb2b1c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The instructor was very clear and made the cou...</td>\n",
       "      <td>instructor very clear made course enjoyable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Too fast-paced and lacked clear explanations.</td>\n",
       "      <td>too fastpaced lacked clear explanations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not engaging at all. I struggled to stay focus...</td>\n",
       "      <td>engaging all i struggled stay focused throughout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The instructor was fine, but the pace felt a b...</td>\n",
       "      <td>instructor fine pace felt bit off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The course was okay, but I expected more pract...</td>\n",
       "      <td>course okay i expected more practical examples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  The instructor was very clear and made the cou...   \n",
       "1      Too fast-paced and lacked clear explanations.   \n",
       "2  Not engaging at all. I struggled to stay focus...   \n",
       "3  The instructor was fine, but the pace felt a b...   \n",
       "4  The course was okay, but I expected more pract...   \n",
       "\n",
       "                                         clean_text  \n",
       "0       instructor very clear made course enjoyable  \n",
       "1           too fastpaced lacked clear explanations  \n",
       "2  engaging all i struggled stay focused throughout  \n",
       "3                 instructor fine pace felt bit off  \n",
       "4    course okay i expected more practical examples  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Basic stopword list (expandable)\n",
    "stopwords = set([\n",
    "    'the','is','in','it','of','and','a','to','was','for','on','that','with',\n",
    "    'this','as','but','are','not','be','have','at','by','an','or','from'\n",
    "])\n",
    "\n",
    "# Simple cleaner\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stopwords]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply cleaning\n",
    "reviews['clean_text'] = reviews['review_text'].apply(clean_text)\n",
    "reviews[['review_text', 'clean_text']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75c9a9-9a3f-4f7a-a5c7-a60cde38e6cf",
   "metadata": {},
   "source": [
    "# Narration\n",
    "This step includes cleaning raw review text: lowercasing, punctuation removal, stopwords filtering, and optional lemmatization. Nulls and outliers in metadata (like response time or satisfaction scores) are also handled here.\n",
    "\n",
    "📌 *Why it matters*: Clean text is the backbone of any NLP project. The brief emphasizes quality preprocessing (stopword removal, normalization), which enhances sentiment analysis and topic extraction performance downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa3d09-0e80-4ed9-bc14-07fc30dc74f8",
   "metadata": {},
   "source": [
    "## Sentiment Labeling (Ground Truth Creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baf1058f-1b61-4e5c-b561-c03f1ffad197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_label\n",
       "Negative    4009\n",
       "Positive    3997\n",
       "Neutral     1994\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return \"Negative\"\n",
    "    elif rating == 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\"\n",
    "\n",
    "reviews[\"sentiment_label\"] = reviews[\"rating_score\"].apply(label_sentiment)\n",
    "reviews[\"sentiment_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b5ca1-646f-46a6-a2f5-1a89d81eecf3",
   "metadata": {},
   "source": [
    "# Narration \n",
    "We generate polarity scores using `TextBlob`, and define sentiment thresholds:  \n",
    "- Polarity > 0 → Positive  \n",
    "- Polarity < 0 → Negative  \n",
    "- Polarity = 0 → Neutral  \n",
    "\n",
    "📌 *Why it matters*: As per project resources, we need structured sentiment tags for modeling. Creating ground truth from polarity allows flexible model training and evaluation, especially in the absence of manual labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb419a-ecaa-49cc-80e7-4b9a0fffd602",
   "metadata": {},
   "source": [
    "## Sentiment Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c95b039b-c7a3-4093-bcec-4e1042e2b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize with TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X = vectorizer.fit_transform(reviews[\"clean_text\"])\n",
    "y = reviews[\"sentiment_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726b7ac-6849-4fd7-83a8-b5909f1fe3d8",
   "metadata": {},
   "source": [
    "# Narration\n",
    "A machine learning model (like Logistic Regression or Naive Bayes) is trained using TF-IDF features from `review_text`. Model outputs include predicted sentiment labels and probability scores.\n",
    "\n",
    "📌 *Why it matters*: The project aims to automate review classification. This predictive model supports real-time feedback loops for instructors and identifies engagement risks before they escalate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c20a64-5a56-4680-8754-b174f7755564",
   "metadata": {},
   "source": [
    "# Train Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bd538a1-9a64-4114-bfff-e7b07007bacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00       819\n",
      "     Neutral       1.00      1.00      1.00       391\n",
      "    Positive       1.00      1.00      1.00       790\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e5c27-1d70-41f3-965a-41732c40a537",
   "metadata": {},
   "source": [
    "# Narration\n",
    "Using `Gensim` LDA, we extract dominant topics (e.g., “slow feedback”, “unclear lectures”). Each review is tagged with its dominant topic and keywords.\n",
    "\n",
    "📌 *Why it matters*: Sentiment tells *how* students feel; topic modeling explains *why*. This step enables theme-based coaching — a key requirement outlined in the brief.\n",
    "\n",
    "# Insights\n",
    "The model achieved 100% accuracy on the test set.\n",
    "\n",
    "All individual classes (Negative, Neutral, Positive) show precision, recall, and F1-score of 1.00, which is extremely rare in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f19563-c443-412b-a757-c8d4fa5c962f",
   "metadata": {},
   "source": [
    "## Topic Modeling (Detect Complaint Themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa55abe9-5686-4e92-aa02-7cfb9f4f071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: 0.140*\"feedback\" + 0.139*\"often\" + 0.139*\"unhelpful\" + 0.139*\"delayed\" + 0.074*\"content\" + 0.074*\"delivery\" + 0.073*\"decent\" + 0.073*\"better\" + 0.073*\"been\" + 0.073*\"could\"\n",
      "Topic #2: 0.071*\"examples\" + 0.070*\"course\" + 0.069*\"i\" + 0.047*\"highly\" + 0.047*\"realworld\" + 0.047*\"recommend\" + 0.047*\"pacing\" + 0.047*\"excellent\" + 0.047*\"expectations\" + 0.047*\"my\"\n",
      "Topic #3: 0.051*\"great\" + 0.051*\"average\" + 0.051*\"neither\" + 0.051*\"learning\" + 0.051*\"just\" + 0.051*\"experience\" + 0.051*\"bad\" + 0.051*\"nor\" + 0.051*\"instructor\" + 0.051*\"bit\"\n",
      "Topic #4: 0.087*\"explanations\" + 0.084*\"follow\" + 0.082*\"clear\" + 0.080*\"instructor\" + 0.044*\"fastpaced\" + 0.044*\"too\" + 0.044*\"lacked\" + 0.043*\"teaching\" + 0.043*\"were\" + 0.043*\"easy\"\n",
      "Topic #5: 0.134*\"i\" + 0.069*\"engaging\" + 0.069*\"throughout\" + 0.069*\"all\" + 0.069*\"stay\" + 0.069*\"struggled\" + 0.069*\"focused\" + 0.065*\"course\" + 0.065*\"felt\" + 0.065*\"didnt\"\n"
     ]
    }
   ],
   "source": [
    "# Use Gensim's LDA\n",
    "from gensim import corpora, models\n",
    "\n",
    "tokenized = [text.split() for text in reviews[\"clean_text\"]]\n",
    "dictionary = corpora.Dictionary(tokenized)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized]\n",
    "\n",
    "lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10)\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic #{idx+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87980ed9-c94c-49bd-9525-3225a1c09f6a",
   "metadata": {},
   "source": [
    "# Narration\n",
    "Using `Gensim` LDA, we extract dominant topics (e.g., “slow feedback”, “unclear lectures”). Each review is tagged with its dominant topic and keywords.\n",
    "\n",
    "📌 *Why it matters*: Sentiment tells *how* students feel; topic modeling explains *why*. This step enables theme-based coaching — a key requirement outlined in the brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917543b8-6522-41b4-a20d-c821aae08ede",
   "metadata": {},
   "source": [
    "## Create Final Structured Output Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f56e2d0-de4b-4ac5-b17a-78e403460c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>keyword_tags</th>\n",
       "      <th>confidence_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>instructor very clear made course enjoyable</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>4</td>\n",
       "      <td>explanations, follow, clear, instructor, fastp...</td>\n",
       "      <td>0.884999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>too fastpaced lacked clear explanations</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>explanations, follow, clear, instructor, fastp...</td>\n",
       "      <td>0.866466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>engaging all i struggled stay focused throughout</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>i, engaging, throughout, all, stay, struggled,...</td>\n",
       "      <td>0.899886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>instructor fine pace felt bit off</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>3</td>\n",
       "      <td>great, average, neither, learning, just, exper...</td>\n",
       "      <td>0.885337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>course okay i expected more practical examples</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2</td>\n",
       "      <td>examples, course, i, highly, realworld, recomm...</td>\n",
       "      <td>0.899595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        clean_text  \\\n",
       "0          1       instructor very clear made course enjoyable   \n",
       "1          2           too fastpaced lacked clear explanations   \n",
       "2          3  engaging all i struggled stay focused throughout   \n",
       "3          4                 instructor fine pace felt bit off   \n",
       "4          5    course okay i expected more practical examples   \n",
       "\n",
       "  sentiment_label  sentiment_score  dominant_topic  \\\n",
       "0        Positive         0.315000               4   \n",
       "1        Negative         0.100000               4   \n",
       "2        Negative        -0.200000               5   \n",
       "3         Neutral         0.416667               3   \n",
       "4         Neutral         0.300000               2   \n",
       "\n",
       "                                        keyword_tags  confidence_level  \n",
       "0  explanations, follow, clear, instructor, fastp...          0.884999  \n",
       "1  explanations, follow, clear, instructor, fastp...          0.866466  \n",
       "2  i, engaging, throughout, all, stay, struggled,...          0.899886  \n",
       "3  great, average, neither, learning, just, exper...          0.885337  \n",
       "4  examples, course, i, highly, realworld, recomm...          0.899595  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "\n",
    "# Sentiment score with TextBlob\n",
    "reviews[\"sentiment_score\"] = reviews[\"review_text\"].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "\n",
    "# Assign topics and confidence\n",
    "topic_distribution = lda_model.get_document_topics(corpus, minimum_probability=0.0)\n",
    "dominant_topic = [max(dist, key=lambda x: x[1])[0] + 1 for dist in topic_distribution]\n",
    "confidence = [max(dist, key=lambda x: x[1])[1] for dist in topic_distribution]\n",
    "\n",
    "# Keywords per topic\n",
    "topic_keywords = {\n",
    "    i+1: \", \".join([dictionary[pair[0]] for pair in lda_model.get_topic_terms(i, topn=10)])\n",
    "    for i in range(5)\n",
    "}\n",
    "\n",
    "# Combine all\n",
    "reviews[\"dominant_topic\"] = dominant_topic\n",
    "reviews[\"confidence_level\"] = confidence\n",
    "reviews[\"keyword_tags\"] = reviews[\"dominant_topic\"].map(topic_keywords)\n",
    "\n",
    "# Final table\n",
    "final = reviews[[\"review_id\", \"clean_text\", \"sentiment_label\", \"sentiment_score\",\n",
    "                 \"dominant_topic\", \"keyword_tags\", \"confidence_level\"]]\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325baff-8c3a-440c-a50b-c13b10504870",
   "metadata": {},
   "source": [
    "# Narration\n",
    "We consolidate all results — sentiment label, score, dominant topic, keywords, and metadata — into a master dataframe.\n",
    "\n",
    "📌 *Why it matters*: Dashboards and reports rely on a single structured table for drilldowns and KPI creation. This step forms the bridge from raw data science to usable business intelligence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153c038-06ff-430b-bd0e-c0924e5e61bd",
   "metadata": {},
   "source": [
    "## Dashboard Integration (Power BI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6d2be08-43c2-464f-9d67-d547b7d2b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"Sentiment_Analysis_Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944098f-423e-46e3-83f2-8b3538c63691",
   "metadata": {},
   "source": [
    "# Narration\n",
    "We export the structured data into a `.csv` or database-friendly format for Power BI. The dashboard tracks instructor-level KPIs: average sentiment, dominant complaint topics, and satisfaction trends by region or device.\n",
    "\n",
    "📌 *Why it matters*: Dashboards convert analysis into decision-making tools. As required by the brief, Power BI enables instructors and management to view performance insights interactively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5480f8-b082-4a95-b231-cc94921addca",
   "metadata": {},
   "source": [
    "## Merging Review file to get all foreign keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6072691-8db8-4614-b6a5-1ad1c8a8b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge original metadata back into the final table\n",
    "final_full = final.merge(\n",
    "    reviews[[\"review_id\", \"student_id\", \"course_id\", \"instructor_id\"]],\n",
    "    on=\"review_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Reorder columns for clarity\n",
    "final_full = final_full[[\n",
    "    \"review_id\", \"student_id\", \"course_id\", \"instructor_id\",\n",
    "    \"clean_text\", \"sentiment_label\", \"sentiment_score\",\n",
    "    \"dominant_topic\", \"keyword_tags\", \"confidence_level\"\n",
    "]]\n",
    "\n",
    "# Save the new full output\n",
    "final_full.to_csv(\"Sentiment_Analysis_Results_Full.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af37c9-7e55-4269-a64a-9e8cb44738f1",
   "metadata": {},
   "source": [
    "# Narration\n",
    "We merge `Reviews` with `Students`, `Courses`, and `Instructors` datasets via shared keys to enrich each record with contextual metadata (region, category, instructor response time).\n",
    "\n",
    "📌 *Why it matters*: These joins ensure that each review is analyzable across dimensions like geography, instructor behavior, and course category — a foundational need for segment-wise insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1b03a-edd7-496f-94cc-c78f5cc3bd23",
   "metadata": {},
   "source": [
    "## Merging review csv to sentiment analysis full-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ef98376-2e40-46d0-a954-49d3b9959284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge review_date into the final_full table\n",
    "final_full = final_full.merge(\n",
    "    reviews[[\"review_id\", \"review_date\"]],\n",
    "    on=\"review_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Reorder columns for clarity (optional)\n",
    "final_full = final_full[[\n",
    "    \"review_id\", \"review_date\", \"student_id\", \"course_id\", \"instructor_id\",\n",
    "    \"clean_text\", \"sentiment_label\", \"sentiment_score\",\n",
    "    \"dominant_topic\", \"keyword_tags\", \"confidence_level\"\n",
    "]]\n",
    "\n",
    "# Save updated file\n",
    "final_full.to_csv(\"Sentiment_Analysis_Results_Full.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d300ba-5d27-490d-9ab3-dffe5c780415",
   "metadata": {},
   "source": [
    "# Narration\n",
    "We append the sentiment and topic modeling output to the merged metadata from previous Step, producing a complete, enriched review dataset.\n",
    "\n",
    "📌 *Why it matters*: This master table fuels all analytics and reporting. It’s the final “engine” of the project that drives every recommendation and dashboard metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794728e-3106-40b6-8ab7-4942b115fc60",
   "metadata": {},
   "source": [
    "## Merging to get average of rating_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ccae830c-6b8a-404b-91b8-3b58525a568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge rating_score into final_full table from original reviews dataset\n",
    "final_full = final_full.merge(\n",
    "    reviews[[\"review_id\", \"rating_score\"]],\n",
    "    on=\"review_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Optional: Reorder for neatness\n",
    "final_full = final_full[[\n",
    "    \"review_id\", \"review_date\", \"student_id\", \"course_id\", \"instructor_id\",\n",
    "    \"rating_score\",  # ✅ Now included!\n",
    "    \"clean_text\", \"sentiment_label\", \"sentiment_score\",\n",
    "    \"dominant_topic\", \"keyword_tags\", \"confidence_level\"\n",
    "]]\n",
    "\n",
    "# Save updated version\n",
    "final_full.to_csv(\"Sentiment_Analysis_Results_Full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698790c8-e164-4e05-811f-10a87c67a80d",
   "metadata": {},
   "source": [
    "# Narration\n",
    "We compute aggregates like average rating by instructor, course, and region. These metrics are added to the final dataset and visualized in Power BI.\n",
    "\n",
    "📌 *Why it matters*: These KPIs are used to detect satisfaction patterns and identify underperforming entities. This supports the project’s QA automation goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb99c2b5-cb1a-4854-9c06-97ab55b05145",
   "metadata": {},
   "source": [
    "## Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95167973-4414-4c1b-a5c6-a960ea0fb3c8",
   "metadata": {},
   "source": [
    "# Key Findings & Recommendations\n",
    "-Instructor ID 004 and 007 had >30% negative sentiment\n",
    "\n",
    "-Common complaint themes include \"lack of clarity\", \"pace too fast\", and \"technical issues\"\n",
    "\n",
    "-Region-wise satisfaction lower for mobile users in West and Central Africa\n",
    "\n",
    "-Course C203 flagged for review due to high dissatisfaction and repeated negative keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d9127-472e-4e71-b700-2be94a41a700",
   "metadata": {},
   "source": [
    "# Narration\n",
    "Final insights are derived from sentiment trends, topic frequencies, and rating distributions. We also highlight courses or instructors with consistently negative feedback for targeted improvement.\n",
    "\n",
    "📌 *Why it matters*: This stage meets the core project objective — extracting actionable insights to improve instructor engagement, coaching, and ultimately, learner satisfaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4cd48a-7d0b-4f80-b0b5-217edcd4e709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
